{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework \\#05\n",
    "### Deep Learning Course $\\in$ DSSC @ UniTS (Spring 2021)  \n",
    "\n",
    "#### Submitted by [Emanuele Ballarin](mailto:emanuele@ballarin.cc)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:\n",
    "\n",
    "We start off by importing all the libraries, modules, classes and functions we are going to use *today*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System interaction\n",
    "import os\n",
    "\n",
    "# Typing\n",
    "from torch import Tensor\n",
    "\n",
    "# Tensor computation and ANNs\n",
    "import torch        # Backward compatibility\n",
    "import torch as th  # Forward compatibility\n",
    "\n",
    "# Scripted easers\n",
    "from scripts import mnist, train_utils, architectures, train\n",
    "from scripts.torch_utils import use_gpu_if_possible\n",
    "from scripts.train_utils import accuracy, AverageMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruning utility functions and related utilities\n",
    "\n",
    "Taken from the provided *Jupyter* notebook, and slightly adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_pruning(model, pruning_rate, layers_to_prune=[\"1\", \"4\", \"7\", \"10\"], init_mask=None):\n",
    "\n",
    "    # Handle base case\n",
    "    if init_mask is None:\n",
    "        init_mask = [1]*len(model.named_parameters())   # Identity mask\n",
    "    # else:\n",
    "    #     init mask = init_mask\n",
    "\n",
    "    params_to_prune = [pars[1] for pars in model.named_parameters() if any([l in pars[0] for l in layers_to_prune])]\n",
    "    flat = torch.cat([pars.abs().flatten() for pars in params_to_prune], dim=0)\n",
    "\n",
    "    flat = flat.sort()[0]\n",
    "    position = int(pruning_rate * flat.shape[0])\n",
    "    thresh = flat[position]\n",
    "\n",
    "    mask = []\n",
    "    maskidx = 0\n",
    "    for pars in model.named_parameters():\n",
    "        if any([l in pars[0] for l in layers_to_prune]) and init_mask[maskidx] == 1:\n",
    "            m = torch.where(pars[1].abs() >= thresh, 1, 0)\n",
    "            mask.append(m)\n",
    "            pars[1].data *= m\n",
    "        else:\n",
    "            mask.append(torch.ones_like(pars[1]))\n",
    "        \n",
    "        maskidx += 1\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Training with pruning* routine\n",
    "\n",
    "Taken from the provided *Jupyter* notebook, and slightly adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, performance_meter, performance, device, mask, layers_to_prune, params_type_to_prune):\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        y_hat = model(X)\n",
    "\n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if mask is not None:\n",
    "            for (name, param), m in zip(model.named_parameters(), mask):\n",
    "                if any([l in name for l in layers_to_prune]):\n",
    "                    param.grad *= m\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = performance(y_hat, y)\n",
    "\n",
    "        loss_meter.update(val=loss.item(), n=X.shape[0])\n",
    "        performance_meter.update(val=acc, n=X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, num_epochs, checkpoint_loc=None, checkpoint_name=\"checkpoint.pt\", performance=accuracy, lr_scheduler=None, device=None, mask=None, params_type_to_prune=[\"weight\", \"bias\"]):\n",
    "    if checkpoint_loc is not None:\n",
    "        os.makedirs(checkpoint_loc, exist_ok=True)\n",
    "\n",
    "    if device is None:\n",
    "        device = use_gpu_if_possible()\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        performance_meter = AverageMeter()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} --- learning rate {optimizer.param_groups[0]['lr']:.5f}\")\n",
    "\n",
    "        train_epoch(model, dataloader, loss_fn, optimizer, loss_meter, performance_meter, performance, device, mask, layers_to_prune, params_type_to_prune)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} completed. Loss - total: {loss_meter.sum} - average: {loss_meter.avg}; Performance: {performance_meter.avg}\")\n",
    "\n",
    "        if checkpoint_name is not None and checkpoint_loc is not None:\n",
    "            checkpoint_dict = {\n",
    "                \"parameters\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch\n",
    "            }\n",
    "            torch.save(checkpoint_dict, os.path.join(checkpoint_loc, checkpoint_name))\n",
    "        \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    return loss_meter.sum, performance_meter.avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('RDDL': conda)",
   "name": "python388jvsc74a57bd04665a7ab5f73937e17a5e61da1e18d3b6b9921930ee46fb6de3bfba5784f1ea7"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "8aec2e4cca6a43ecda9b11f31ea0f9f4b012d28e6de8cbdf64a5e136ca9a5fb0"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}