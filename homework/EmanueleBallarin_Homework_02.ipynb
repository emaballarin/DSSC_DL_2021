{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Deep Learning Homework \\#02\n", "### Deep Learning Course $\\in$ DSSC @ UniTS (Spring 2021)  \n", "\n", "#### Submitted by [Emanuele Ballarin](mailto:emanuele@ballarin.cc)  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Request:\n", "\n", "Try to reproduce in *PyTorch* the first experiment from [*Learning representations by back-propagating errors*](https://sci-hub.do/10.1038/323533a0) with learning rule from *eq. 8* (i.e. *gradient descent without momentum*).\n", "\n", "Try to be as close as possible to the original protocol, except for what regards the learning rule, and perhaps the random initialization method.\n", "\n", "1. Read the paper;\n", "\n", "2. Create the data, the model and everything needed;\n", "\n", "3. Train the model;\n", "\n", "4. Inspect the weights you obtained and check if they provide a solution to the problem;\n", "\n", "Compare the solution to the solution reported in the paper."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Imports:\n", "\n", "We start off by importing all the libraries, modules, classes and functions we are going to use *today*..."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# Type hints\n", "from typing import Union, Iterable\n", "from torch import Tensor\n", "\n", "# Just to force-load MKL (if available)\n", "import numpy as np\n", "\n", "# Neural networks and friends\n", "import torch as th\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "\n", "# High-level abstractions over PyTorch primitives\n", "from ebtorch.nn import FCBlock\n", "\n", "# Model summarization\n", "from torchinfo import summary\n", "\n", "# Dataset handling for PyTorch\n", "from torch.utils.data import TensorDataset\n", "from torch.utils.data import DataLoader\n", "\n", "# Permutation building easer\n", "from itertools import product\n", "\n", "# Plotting the loss function\n", "from matplotlib import pyplot as plt\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Dataset building & DataLoading:\n", "\n", "We now face (and hopefully solve) the issue of building the (synthetic) dataset for the *supervised learning* problem we want to tackle.  \n", "\n", "It is composed of:\n", "\n", "- All (64 in total) possible 6-element lists of ${0,1}$ Boolean values; $X$\n", "- The true target (binary) class: one among *endowed with mirror symmetry* or *not endowed with mirror symmetry*, according to -- indeed -- the property of the first half of the list (positions 1 to 3) being mirrored by the second half (positions 4 to 6); $Y$\n", "\n", "As an example:\n", "- The list `[0,1,1,1,0,1]` will be *not endowed with mirror symmetry*, whereas\n", "- The list `[1,1,0,0,1,1]` will be *endowed with mirror symmetry*."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Obtain the true target class (output) from any valid iterable input\n", "def mirrsymm(iterable: Iterable) -> float:\n", "    assert len(iterable) == 6\n", "    # if iterable[0:3] == iterable[5:2:-1]:\n", "    # Missing support from PyTorch side for this; what a pity!\n", "    # What follows is the easiest non-copying version of the mirror condition :\\\n", "    if (\n", "        iterable[0] == iterable[-1]\n", "        and iterable[1] == iterable[-2]\n", "        and iterable[2] == iterable[-3]\n", "    ):\n", "        return 1.0\n", "    return 0.0\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Obtain all possible inputs (thanks, itertools!)\n", "x: Tensor = th.tensor(\n", "    [item for item in product([0.0, 1.0], repeat=6)], dtype=th.float32\n", ")\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Obtain all corresponding outputs (thanks, crazily-flexible comprehensions!)\n", "y: Tensor = th.tensor([[mirrsymm(myin)] for myin in x])\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Define training data[set | loader]\n", "train = TensorDataset(x, y)\n", "train_loader = DataLoader(\n", "    train, batch_size=64, shuffle=True\n", ")  # We do full-dataset GD, not a gain in shuffling (unless we experiment with different batch sizes!)\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Define testing data[set | loader]; useful (in this case) if experimenting with multiple batch sizes\n", "train = TensorDataset(x, y)\n", "train_loader = DataLoader(\n", "    train, batch_size=64, shuffle=False\n", ")  # We do full-dataset GD, not a gain in shuffling\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Defining the model:\n", "\n", "Now we need to build our model.  \n", "\n", "What the original paper shows is (in a nowadays unusual canon) a *fully-connected feedforward block* with input size of $6$, output size of $1$ and one set of $2$ hidden units, connected via two hidden layers (we adopt here the definition of *layer* as an *affine operator*) of sizes, respectively, $6$-to-$2$ and $2$-to-$1$.  \n", "\n", "As written in the experiment description, we will always use *neurons* with bias and the *Sigmoid* activation (both as hidden and output activation function).  \n", "\n", "Particular care must be taken in order to initialize network weights as described in the original paper. However, thanks to PyTorch, such care often reduces to some looping and one pre-made function call."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["# The model, defined using ebtorch's FC API ;)\n", "model = FCBlock(\n", "    fin=6,\n", "    hsizes=[2],\n", "    fout=1,\n", "    hactiv=th.sigmoid,\n", "    # hactiv=F.hardsigmoid,\n", "    # hactiv=F.hardtanh,\n", "    oactiv=th.sigmoid,\n", "    # oactiv=F.hardsigmoid,\n", "    # oactiv=lambda x: th.round(th.sigmoid(x)),\n", "    bias=True,\n", ")\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["# The \"standard\" alternative\n", "class myMLP(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        # Layers:\n", "        self.layer1 = nn.Linear(in_features=6, out_features=2, bias=True)\n", "        self.layer2 = nn.Linear(in_features=2, out_features=1, bias=True)\n", "        # Stateful functions:\n", "        # Since ReLU and SoftMax are stateless, no cruft here!\n", "\n", "    def forward(self, x):\n", "        x = self.layer1(x)\n", "        x = th.sigmoid(x)\n", "        x = self.layer2(x)\n", "        x = th.sigmoid(x)\n", "        return x\n", "\n", "\n", "# model_std = myMLP()\n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": "=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n\u251c\u2500ModuleList: 1-1                        --\n|    \u2514\u2500Linear: 2-1                       14\n|    \u2514\u2500Linear: 2-2                       3\n=================================================================\nTotal params: 17\nTrainable params: 17\nNon-trainable params: 0\n================================================================="}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["# \"It's better to look once more at a model that you expect rather\n", "# than risking to use one you don't\"\n", "#                                      (Yaroslav Bulatov *)\n", "# * the guy behind \"ImageNet in 18 minutes\"\n", "summary(model)\n", "# summary(model_std)\n"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# Initialize model weights\n", "extr = 0.3\n", "for param in model.parameters():\n", "    # \"random and uniformly distributed between -0.3 and 0.3\"\n", "    nn.init.uniform_(param, a=-extr, b=extr)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Training *loop* and *mechanics*:\n", "\n", "The following section os devoted to the training of the model, and the *put-into-place* of anything needed to actually perform the training and continuously monitor its loss.  \n", "\n", "Since the *training set* just exhausts all possible inputs for the model, *testing-on-train* is the only available option for loss monitoring."]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["# Instantiate the optimizer (hyperparameters from the paper; but no momentum!)\n", "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.0)\n"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": ["# Instantiate the loss criterion\n", "criterion = F.mse_loss\n"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["# Keep track of the loss/accuracy on a per-epoch basis\n", "losses = []\n", "accuracies = []\n"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": "FCBlock(\n  (linears): ModuleList(\n    (0): Linear(in_features=6, out_features=2, bias=True)\n    (1): Linear(in_features=2, out_features=1, bias=True)\n  )\n)"}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["# Actual training loop\n", "\n", "model.train()  # Not strictly needed *here*, but a good practice!\n", "\n", "for epoch in range(1425):\n", "    for x, y in train_loader:\n", "\n", "        # Per-batch mechanics\n", "        optimizer.zero_grad()\n", "        y_hat = model(x)\n", "        loss = criterion(y_hat, y)\n", "        losses.append(\n", "            loss.item()\n", "        )  # We just want the number, not the whole computational graph attached!\n", "\n", "        # Compute accuracy on-the-fly (since batch == dataset)\n", "        with th.no_grad():\n", "            out = th.round(model(x))\n", "            accuracies.append((out.eq(y.view_as(out))).sum().item() / 64.0)\n", "\n", "        # Business as usual...\n", "        loss.backward()\n", "        optimizer.step()\n", "\n", "model.eval()  # Not strictly needed *here*, but a good practice!\n"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/plain": "[<matplotlib.lines.Line2D at 0x7fe868f8cc70>]"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}, {"data": {"image/png": "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\n", "text/plain": "<Figure size 432x288 with 1 Axes>"}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["plt.plot(losses)\n"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"data": {"text/plain": "[<matplotlib.lines.Line2D at 0x7fe868e729a0>]"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}, {"data": {"image/png": "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\n", "text/plain": "<Figure size 432x288 with 1 Axes>"}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["plt.plot(accuracies)\n"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["tensor([[ 0.1645,  0.2446,  0.0539, -0.1483, -0.0861,  0.2461],\n", "        [-0.1556,  0.2733,  0.0976, -0.1093, -0.0681, -0.1610]])\n", "tensor([0.1746, 0.1764])\n", "tensor([[-0.5142, -0.7898]])\n", "tensor([-1.2198])\n"]}], "source": ["with th.no_grad():\n", "    for param in model.parameters():\n", "        print(param.detach().clone())\n"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0.10941808670759201\n", "0.875\n"]}], "source": ["print(losses[-1])\n", "print(accuracies[-1])\n"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0.0 1.0 \n", "\n", "0.0 1.0 \n", "\n", "0.0 1.0 \n", "\n", "0.0 1.0 \n", "\n", "0.0 1.0 \n", "\n", "0.0 1.0 \n", "\n", "0.0 1.0 \n", "\n", "0.0 1.0 \n", "\n"]}], "source": ["with th.no_grad():\n", "    for mirrorlist in [\n", "        [0, 0, 0, 0, 0, 0],\n", "        [0, 0, 1, 1, 0, 0],\n", "        [0, 1, 0, 0, 1, 0],\n", "        [1, 0, 0, 0, 0, 1],\n", "        [0, 1, 1, 1, 1, 0],\n", "        [1, 1, 0, 0, 1, 1],\n", "        [1, 0, 1, 1, 0, 1],\n", "        [1, 1, 1, 1, 1, 1],\n", "    ]:\n", "        print(\n", "            th.round_(\n", "                model(th.tensor(mirrorlist, dtype=th.float32)).detach().clone()\n", "            ).item(),\n", "            mirrsymm(mirrorlist),\n", "            \"\\n\",\n", "        )\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3.8.8 64-bit ('RDDL': conda)", "name": "python388jvsc74a57bd04665a7ab5f73937e17a5e61da1e18d3b6b9921930ee46fb6de3bfba5784f1ea7"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.8"}}, "nbformat": 4, "nbformat_minor": 5}